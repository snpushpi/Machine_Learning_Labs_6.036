{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MIT 6.036 HW07 - PyTorch",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/snpushpi/MIT_machine_learning/blob/master/Copy_of_MIT_6_036_HW07_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JWaIkcl0xwu_",
        "colab_type": "text"
      },
      "source": [
        "# MIT 6.036 Fall 2019: Homework 7 - PyTorch\n",
        "\n",
        "This colab notebook provides code and a framework for homework 7. You can work out your solutions here, then submit your results back on the homework page when ready.\n",
        "\n",
        "**Note**: You can go to `File > Save a copy in Drive...` to save your own copy of this notebook for editing.\n",
        "\n",
        "## Setup\n",
        "\n",
        "First, download the code distribution for this homework that contains test cases and helper functions. Run the next code block to download and import the code for this lab."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "POU9z7ShiOHv",
        "outputId": "6b221d1d-b9e8-4ee4-b74f-6b09cfc27da3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        }
      },
      "source": [
        "!rm -rf code_for_hw7 data\n",
        "!wget --quiet https://introml.odl.mit.edu/cat-soop/_static/6.036/homework/hw07/code_for_hw7.zip\n",
        "!unzip code_for_hw7.zip\n",
        "!mv code_for_hw7/* ."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  code_for_hw7.zip\n",
            "   creating: code_for_hw7/\n",
            "  inflating: code_for_hw7/code_for_hw7.py  \n",
            "  inflating: code_for_hw7/code_for_hw7_pytorch.py  \n",
            "   creating: code_for_hw7/data/\n",
            "  inflating: code_for_hw7/data/data1_train.csv  \n",
            "  inflating: code_for_hw7/data/data1_validate.csv  \n",
            "  inflating: code_for_hw7/data/data2_train.csv  \n",
            "  inflating: code_for_hw7/data/data2_validate.csv  \n",
            "  inflating: code_for_hw7/data/data3class_train.csv  \n",
            "  inflating: code_for_hw7/data/data3_train.csv  \n",
            "  inflating: code_for_hw7/data/data3_validate.csv  \n",
            "  inflating: code_for_hw7/data/data4_train.csv  \n",
            "  inflating: code_for_hw7/data/data4_validate.csv  \n",
            "  inflating: code_for_hw7/data/dataXor_train.csv  \n",
            "  inflating: code_for_hw7/expected_results.py  \n",
            "  inflating: code_for_hw7/modules_disp.py  \n",
            "  inflating: code_for_hw7/utils_hw7.py  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EJQvZ_MNyEYQ",
        "colab_type": "text"
      },
      "source": [
        "# 3) 2D Datasets\n",
        "\n",
        "For the 2D datasets, we have provided the following function:\n",
        "\n",
        ">```run_pytorch_2d(data_name, layers, epochs, split=0.25, display=True, trials=5)```\n",
        "\n",
        "where:\n",
        "\n",
        "* `data_name` is a string, such as '1', '2', etc. \n",
        "* `layers` is a list of torch.nn layer definitions for a Sequential model, e.g.\n",
        "> ```[Linear(in_features=2, out_features=classes, bias=True), Softmax(dim=-1)]```\n",
        "* `epochs` is an integer indicating how many times to go through the data in training \n",
        "* `split` is a fraction of the training data to use for validation if a validation set is not defined \n",
        "* `display` whether to display result plots \n",
        "* `verbose` whether to print loss and accuracy (percent correctly labeled) each epoch \n",
        "* `trials` is an integer indicating how many times to perform the training and testing \n",
        "\n",
        "The two-class datasets have `data_name`s: `'1'`,`'2'`,`'3'`,`'4'`.\n",
        "\n",
        "In this problem, try the following 5 architectures, specified by the number of units in the hidden layers:\n",
        "\n",
        "`0: (), 1: (10), 2: (100), 3: (10, 10), 4: (100, 100)`\n",
        "\n",
        "You may find the `archs` function below to be helpful here. Some of these questions ask for the \"simplest\" architecture; the list above is ordered starting with the simplest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eciSdje5J5vV",
        "colab_type": "text"
      },
      "source": [
        "## Helper Functions\n",
        "\n",
        "The following functions will train a neural network in PyTorch. You do not need to edit them but please try to go through them. There is a **Playground** section below that shows how to run these methods for the homework."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIkE7hqmgE1c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from utils_hw7 import plot_heat, get_data_loader, model_fit, model_evaluate, run_pytorch, dataset_paths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U34tpL0QK96Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import itertools\n",
        "import math as m\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaY64c3h6Hd0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.nn import Linear, ReLU, Softmax, Sequential, CrossEntropyLoss\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "\n",
        "######################################################################\n",
        "# Problem 3 - 2D data\n",
        "######################################################################\n",
        "\n",
        "def archs(classes):\n",
        "    return {0: [Linear(in_features=2, out_features=classes, bias=True),\n",
        "             Softmax(dim=-1)],\n",
        "            \n",
        "            1: [Linear(in_features=2, out_features=10, bias=True),\n",
        "             ReLU(),\n",
        "             Linear(in_features=10, out_features=classes, bias=True),\n",
        "             Softmax(dim=-1)],\n",
        "\n",
        "            2: [Linear(in_features=2, out_features=100, bias=True),\n",
        "             ReLU(),\n",
        "             Linear(in_features=100, out_features=classes, bias=True),\n",
        "             Softmax(dim=-1)],\n",
        "            \n",
        "            3: [Linear(in_features=2, out_features=10, bias=True),\n",
        "             ReLU(),\n",
        "             Linear(in_features=10, out_features=10, bias=True),\n",
        "             ReLU(),\n",
        "             Linear(in_features=10, out_features=classes, bias=True),\n",
        "             Softmax(dim=-1)],\n",
        "\n",
        "            4: [Linear(in_features=2, out_features=100, bias=True),\n",
        "             ReLU(),\n",
        "             Linear(in_features=100, out_features=100, bias=True),\n",
        "             ReLU(),\n",
        "             Linear(in_features=100, out_features=classes, bias=True),\n",
        "             Softmax(dim=-1)]\n",
        "           }\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Poe-4fk7Gop7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This function is also in utils_hw7.\n",
        "We write it here just to bring it to your attention.\n",
        "Please try to go through it.\n",
        "\"\"\"\n",
        "\n",
        "def call_model(mode, model, data_iter, optimizer, criterion):\n",
        "    epoch_loss = []\n",
        "    hits = []\n",
        "    items = []\n",
        "    \n",
        "    if mode == 'train':\n",
        "        model.train()\n",
        "        grad_mode = torch.enable_grad()\n",
        "    else:\n",
        "        model.eval()\n",
        "        grad_mode = torch.no_grad()\n",
        "\n",
        "    with grad_mode:\n",
        "\n",
        "        for batch in data_iter:\n",
        "            X, y = batch.X, batch.y\n",
        "\n",
        "            if mode == 'train':\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "            # forward\n",
        "            y_hat = model(X)\n",
        "            batch_loss = criterion(y_hat, y.long())\n",
        "\n",
        "            if mode == 'train':\n",
        "                # backward + optimize\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "            epoch_loss.append(batch_loss.item())\n",
        "            hits.append((y_hat.argmax(1) == y).sum())\n",
        "            items.append(X.shape[0])\n",
        "\n",
        "        loss = np.sum(epoch_loss)/np.sum(items)\n",
        "        acc_score = np.sum(hits)/np.sum(items)\n",
        "        return loss, acc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azz2Ou-i98Ui",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "This function is also in utils_hw7.\n",
        "We write it here just to bring it to your attention because\n",
        "you'll be running (but not modifying) this function for this\n",
        "homework.\n",
        "Please try to go through it.\n",
        "\"\"\"\n",
        "\n",
        "def run_pytorch_2d(data_name, layers, epochs, split=0.25, display=True,\n",
        "                   verbose=True, trials=1, batch_size=32):\n",
        "    print('Pytorch FC: dataset=', data_name)\n",
        "    (train_dataset_path, val_dataset_path, test_dataset_path) = dataset_paths(data_name)\n",
        "    # Load the datasets\n",
        "    train_iter, num_classes = get_data_loader(train_dataset_path, batch_size)\n",
        "    val_iter, num_classes = get_data_loader(val_dataset_path, batch_size)\n",
        "    test_iter, num_classes = get_data_loader(test_dataset_path, batch_size)\n",
        "    \n",
        "    if val_iter is None:\n",
        "        # Use split\n",
        "        print(\"Use split\", train_iter)\n",
        "        assert split > 0, '`split` must be > 0'\n",
        "        train_iter, val_iter,  num_classes = get_data_loader(train_dataset_path, batch_size, split)\n",
        "\n",
        "    val_acc, test_acc = 0, 0\n",
        "    X_train = torch.cat([batch.X for batch in train_iter], 0)\n",
        "    y_train = torch.cat([batch.y for batch in train_iter], 0)\n",
        "    \n",
        "    for trial in range(trials):\n",
        "        trial_history = {'epoch_loss': [], 'epoch_val_loss': [],\n",
        "               'epoch_acc': [], 'epoch_val_acc': []}\n",
        "    \n",
        "        if verbose: print(\"\\n\")\n",
        "        print(f'# Trial {trial}')\n",
        "        \n",
        "        # Run the model\n",
        "        model, vacc, tacc, = run_pytorch(train_iter, val_iter, test_iter, \n",
        "                                         layers, epochs, split=split,\n",
        "                                         verbose=verbose, history=trial_history)\n",
        "\n",
        "        val_acc += vacc if vacc else 0\n",
        "        test_acc += tacc if tacc else 0\n",
        "        if display:\n",
        "            # plot classifier landscape on training data\n",
        "            plot_heat(X_train, y_train, model)\n",
        "            plt.title('Training data')\n",
        "            plt.show()\n",
        "            if test_iter is not None:\n",
        "                # plot classifier landscape on testing data\n",
        "                X_test = torch.cat([batch.X for batch in test_iter], 0)\n",
        "                y_test = torch.cat([batch.y for batch in test_iter], 0)\n",
        "                plot_heat(X_test, y_test, model)\n",
        "                plt.title('Testing data')\n",
        "                plt.show()\n",
        "            # Plot epoch loss\n",
        "            plt.figure(facecolor=\"white\")\n",
        "            plt.plot(range(epochs), trial_history['epoch_loss'], label='epoch_train_loss')\n",
        "            plt.plot(range(epochs), trial_history['epoch_val_loss'], label='epoch_val_loss')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('loss')\n",
        "            plt.title('Epoch val_loss and loss')\n",
        "            plt.legend()\n",
        "            plt.show()\n",
        "            # Plot epoch accuracy\n",
        "            plt.figure(facecolor=\"white\")\n",
        "            plt.plot(range(epochs), trial_history['epoch_acc'], label='epoch_train_acc')\n",
        "            plt.plot(range(epochs), trial_history['epoch_val_acc'], label='epoch_val_acc')\n",
        "            plt.xlabel('epoch')\n",
        "            plt.ylabel('accuracy')\n",
        "            plt.legend()\n",
        "            plt.title('Epoch val_acc and acc')\n",
        "            plt.show()\n",
        "    if val_acc:\n",
        "        print (\"\\nAvg. validation accuracy:\"  + str(val_acc/trials))\n",
        "    if test_acc:\n",
        "        print (\"\\nAvg. test accuracy:\"  + str(test_acc/trials))\n",
        "        \n",
        "   \n",
        "    return X_train, y_train, model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUbidWYsqmDl",
        "colab_type": "text"
      },
      "source": [
        "## 3G)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YvqJbk8dqk_o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "points = np.array([[-1,0], [1,0], [0,-11], [0,1], [-1,-1], [-1,1], [1,1], [1,-1]])\n",
        "\n",
        "deterministic = True\n",
        "if deterministic:\n",
        "  torch.manual_seed(10)\n",
        "  torch.backends.cudnn.deterministic = True\n",
        "  torch.backends.cudnn.benchmark = False\n",
        "  np.random.seed(10)\n",
        "\n",
        "\"\"\"\n",
        "HERE YOUR CODE!!\n",
        "\"\"\"\n",
        "pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnjuKTJXExBZ",
        "colab_type": "text"
      },
      "source": [
        "# Playground"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS_q9fYj8uyI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = run_pytorch_2d(\"2\", archs(2)[4], 120, display=True, verbose=False, trials=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "071X-ooS8uvA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "_ = run_pytorch_2d(\"3class\",archs(3)[2], 10, split=.5, display=False, verbose=False, trials=20)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}